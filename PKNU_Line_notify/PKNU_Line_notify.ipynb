{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 :  2020학년도 학부 코로나19 특별장학금 신청 안내(2차)\n",
      "부서 :  학생복지과 \n",
      "날짜 :  2020-08-21 \n",
      "페이지 :  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "제목 :  2020-2학기 중소기업 취업연계 장학금(희망사다리1) 학생 신청 ...\n",
      "부서 :  학생복지과 \n",
      "날짜 :  2020-09-14 \n",
      "페이지 :  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "제목 :  2020학년도 2학기 교내 특별장학금 추가 신청 안내\n",
      "부서 :  학생복지과 \n",
      "날짜 :  2020-08-31 \n",
      "페이지 :  5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{\"status\":200,\"message\":\"ok\"}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "import time as t\n",
    "\n",
    "base_url = \"http://www.pknu.ac.kr/usrBoardActn.do?p_bm_idx=5&p_boardcode=PK10000005&p_sbsidx=2\"\n",
    "\n",
    "find_data = '장학금'\n",
    "limit_num = 5\n",
    "meta_data = []\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    executable_path=\"webdriver/chromedriver.exe\"\n",
    ")\n",
    "driver.get(base_url)\n",
    "t.sleep(5)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"p_sbsidx\"]/option[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"cateForm\"]/div/input').click()\n",
    "\n",
    "for i in range(limit_num):\n",
    "    t.sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    meta_content = soup.select('td[class=title]')\n",
    "    meta_author = soup.select('td[class=author]')\n",
    "    meta_time = soup.select('td[class=date]')\n",
    "\n",
    "    for tag1, tag2, tag3 in zip(meta_content, meta_author, meta_time):\n",
    "\n",
    "        data_title = tag1.text.strip()\n",
    "        data_author = tag2.text\n",
    "        data_time = tag3.text\n",
    "        status = False\n",
    "        \n",
    "        for temp in meta_data:\n",
    "            if data_title == temp[0]:\n",
    "                status = True\n",
    "                \n",
    "        if status:\n",
    "            continue\n",
    "\n",
    "        if find_data in data_title:\n",
    "            print(\"제목 : \", data_title)\n",
    "            print(\"부서 : \", data_author)\n",
    "            print(\"날짜 : \", data_time)\n",
    "            print(\"페이지 : \", i+1)\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "        data_author = data_author.replace(\"\\xa0\",\"\")\n",
    "        data_time = data_time.replace(\"\\xa0\", \"\")\n",
    "\n",
    "        meta_data.append([data_title, data_author, data_time])\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"contents\"]/div[4]/div[2]/a[' + str(i + 3) + ']').click()\n",
    "\n",
    "t.sleep(5)\n",
    "driver.close()\n",
    "\n",
    "import requests\n",
    "# 요청을 위한 상수를 선언합니다: TOKEN은 자신의 것을 입력해주세요.\n",
    "TARGET_URL = 'https://notify-api.line.me/api/notify'\n",
    "TOKEN = 'D1WCgxDEY4ZiFzNR3TFNuCGskQomSTubIfRhAujLrSG'\n",
    "# 요청합니다.\n",
    "\n",
    "for i in meta_data:\n",
    "    response = requests.post(\n",
    "  TARGET_URL,\n",
    "  headers={\n",
    "    'Authorization': 'Bearer ' + TOKEN\n",
    "  },\n",
    "  data={\n",
    "    'message':i[0]   \n",
    "  }\n",
    ")\n",
    "# 요청 완료\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - *위 코드는 테스트 용입니다*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - 부경대 웹 홈페이지 공지사항을 전해주는 Line 메세지 알람을 만들어보자\n",
    "\n",
    "약 2년간 생각했던 프로젝트가 졸업하고 나서야 이제야 완성하네요...\n",
    "\n",
    "지금까지 부경대학교 공지사항을 추출하고 정리해서 엑셀파일로 취합하고 검색 과정까지 구현하였는데요<br>\n",
    "이렇게까지 해도 신기하고 편리한 과정이지만<br>\n",
    "그러면 매번 파이썬 프로그램을 실행해서 봐야하나...? 라고 의문이 드실 수도 있으실 겁니다\n",
    "\n",
    "사실 더 편리하게 누구보다 빠르게 소식을 접하려면 모바일이 최곱니다<br>\n",
    "저도 옛날부터 그렇게 생각해서 이 프로젝트의 최종점은 어플에서 받아보는 형태가 될 것이라고 예상했었구요\n",
    "\n",
    "---\n",
    "\n",
    "따라서 이번 시간에는 부경대 웹 홈페이지에서 공지사항을 긁어와서 정리한 다음<br>\n",
    "Line 어플 내에 메세지 알람을 만들어서 공지사항 메세지를 보내주는 프로그램을 작성해봅시다\n",
    "\n",
    "참고로 메세지만 유저에게 전달하는 형태이기 때문에 우선 Line Notify로 구현한 다음<br>\n",
    "추가적으로 더 기능을 구현하고자 할 때 Line 챗봇 순으로 진행하겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "base_url = \"http://www.pknu.ac.kr/usrBoardActn.do?p_bm_idx=5&p_boardcode=PK10000005&p_sbsidx=2\"\n",
    "meta_data = []\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    executable_path=\"webdriver/chromedriver.exe\"\n",
    ")\n",
    "driver.get(base_url)\n",
    "sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"p_sbsidx\"]/option[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"cateForm\"]/div/input').click()\n",
    "\n",
    "for i in range(3):\n",
    "    sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    meta_content = soup.select('td[class=title]')\n",
    "    meta_author = soup.select('td[class=author]')\n",
    "    meta_time = soup.select('td[class=date]')\n",
    "\n",
    "    for tag1, tag2, tag3 in zip(meta_content, meta_author, meta_time):\n",
    "\n",
    "        data_title = tag1.text.strip()\n",
    "        data_author = tag2.text\n",
    "        data_time = tag3.text\n",
    "        status = False\n",
    "        \n",
    "        for temp in meta_data:\n",
    "            if data_title == temp[0]:\n",
    "                status = True\n",
    "                \n",
    "        if status:\n",
    "            continue\n",
    "            \n",
    "        data_author = data_author.replace(\"\\xa0\",\"\")\n",
    "        data_time = data_time.replace(\"\\xa0\", \"\")\n",
    "\n",
    "        meta_data.append([data_title, data_author, data_time])\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"contents\"]/div[4]/div[2]/a[' + str(i + 3) + ']').click()\n",
    "\n",
    "t.sleep(2)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음... 우선은 제가 순서는 다음과 같습니다\n",
    "\n",
    "1. 웹 크롤링을 진행하고 결과를 정리한다\n",
    "2. 라인과 연동한다\n",
    "3. 메세지를 보내준다\n",
    "\n",
    "다시 크게 생각하면 또 두 가지를 생각해야 하네요\n",
    "\n",
    " - 메세지를 각 공지사항마다 쪼개서 30개 / 30개씩 보낼지 / 1개에 통합해서 보낼지\n",
    " - 검색결과 메세지는 따로 보낼지\n",
    " \n",
    "생각을 정리해보니 모든 공지사항을 통합해서 하나의 메세지로 보내준 다음<br>\n",
    "검색결과 메세지는 따로 보내서 총 2개의 메세지를 보내는 과정으로 진행하겠습니다\n",
    "    \n",
    "---\n",
    "\n",
    "일단은 우리가 저번 시간에 작성했던 코드들을 잠시만 정리하겠습니다\n",
    " - import time as t를 from time import sleep으로 수정\n",
    " - 검색 및 페이지 수 조절 기능 삭제\n",
    " - 페이지 탐색 수 5로 고정\n",
    " - sleep 시간 모두 2으로 고정\n",
    " \n",
    "코드를 리팩토링하면서 안 거지만 사실 검색은 메세지를 통해서 ~~ 결과입니다 구조가 제일 바람직합니다만<br>\n",
    "현재 notify에 메세지를 처리하는 기능이 있는지 파악을 못했습니다\n",
    "\n",
    "우선 그러면 검색 기능은 후에 챗봇을 구현할 때 하도록 하고<br>\n",
    "이번 시간에는 전체 공지사항을 30개의 메세지 형태로 받아오는 프로그램으로 방향을 잠깐 바꾸겠습니다<br>\n",
    " \n",
    "---\n",
    "\n",
    "검색 및 페이지 제한 기능을 삭제해버리니 딱히 할 건 없네요<br>\n",
    "추가로 10페이지 이상 탐색 테스트를 진행할 때 안 거지만 10페이지 이상부터는 사실 ▶버튼을 이용해서<br>\n",
    "접근을 해야하지만 딱히 그럴 필요 없이 바로 알아서 잘 찾아가더라고요?\n",
    "\n",
    "후에 챗봇을 만들 때도 수고를 덜었으니 다행인듯 합니다\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "추가적으로 사실 제가 현재 진행하고자 하는 과정은 다음과 같습니다\n",
    "\n",
    " - 웹 크롤링을 다한다\n",
    " - 결과를 정리한다\n",
    " - 메세지를 보내준다\n",
    " \n",
    "뭐 지금같은 소규모의 데이터의 경우에는 상관없지만<br>\n",
    "언제나 프로그램은 대량의 데이터를 처리한다는 관점 하에 작성하여야 합니다\n",
    "\n",
    "따라서 위와 같이 모든 과정은 한꺼번에 융합적으로 이루어져야겠죠?<br>\n",
    "페이지당 크롤링이 완료되면 바로바로 메세지를 보낼 수 있도록 수정해야 할 것 같습니다\n",
    "\n",
    "---\n",
    "    \n",
    "음... 그래서 살짝 코드를 또 수정해야겠네요\n",
    " - 페이지당 크롤링을 진행하고 결과가 완료되면\n",
    " - 바로 메세지를 보내버리자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "import requests\n",
    "TARGET_URL = 'https://notify-api.line.me/api/notify'\n",
    "TOKEN = 'D1WCgxDEY4ZiFzNR3TFNuCGskQomSTubIfRhAujLrSG'\n",
    "\n",
    "base_url = \"http://www.pknu.ac.kr/usrBoardActn.do?p_bm_idx=5&p_boardcode=PK10000005&p_sbsidx=2\"\n",
    "meta_data = []\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    executable_path=\"webdriver/chromedriver.exe\"\n",
    ")\n",
    "driver.get(base_url)\n",
    "sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"p_sbsidx\"]/option[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"cateForm\"]/div/input').click()\n",
    "\n",
    "for i in range(3):\n",
    "    msg = ''\n",
    "    sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    meta_content = soup.select('td[class=title]')\n",
    "    meta_author = soup.select('td[class=author]')\n",
    "    meta_time = soup.select('td[class=date]')\n",
    "\n",
    "    for tag1, tag2, tag3 in zip(meta_content, meta_author, meta_time):\n",
    "\n",
    "        data_title = tag1.text.strip()\n",
    "        data_author = tag2.text\n",
    "        data_time = tag3.text\n",
    "        status = False\n",
    "        \n",
    "        for temp in meta_data:\n",
    "            if data_title == temp[0]:\n",
    "                status = True\n",
    "                \n",
    "        if status:\n",
    "            continue\n",
    "            \n",
    "        data_author = data_author.replace(\"\\xa0\",\"\")\n",
    "        data_time = data_time.replace(\"\\xa0\", \"\")\n",
    "\n",
    "        meta_data.append([data_title, data_author, data_time])\n",
    "        msg += data_title + data_author + data_time + \"\\n\"\n",
    "        \n",
    "    response = requests.post(\n",
    "  TARGET_URL,\n",
    "  headers={\n",
    "    'Authorization': 'Bearer ' + TOKEN\n",
    "  },\n",
    "  data={\n",
    "    'message':msg\n",
    "  }\n",
    "    )\n",
    "    print(response.text)\n",
    "    driver.find_element_by_xpath('//*[@id=\"contents\"]/div[4]/div[2]/a[' + str(i + 3) + ']').click()\n",
    "\n",
    "t.sleep(2)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 고민이 되는게 코드는 이런식으로 주욱 써가는 게 아니라<br>\n",
    "반드시 유지 보수를 쉽게 하기 위해서 각 기능마다 모듈화를 해야합니다\n",
    "\n",
    "다만 지금은 일단 완성에 목표가 맞춰져있으니...음...<br>\n",
    "후에 클래스 구조를 이용한 모듈화를 반드시 해야겠습니다\n",
    "\n",
    "하나 고치면 하나 터지고 하나 고치면 코드가 개판되니 항상 고민이군요\n",
    "\n",
    "---\n",
    "\n",
    "우선은 중복 검사를 위해서 반드시 meta_data는 유지해야 하는 것으로 보입니다<br>\n",
    "다만 meta_data를 통째로 메세지로 보내게되면 반드시 개판날 게 뻔하니까<br>\n",
    "페이지 당 meta_data를 메세지로 만들어주는 과정을 중간에 삽입해줍시다\n",
    "\n",
    "msg 변수는 어차피 페이지당 메세지를 하나씩 보낼 거니까 각 페이지마다 초기화 과정을 거쳐줍니다<br>\n",
    "그리고 문자열 변수니까 간단하게 +연산자를 이용해서 각 내용을 계속 붙여주면서 이어줍시다\n",
    "\n",
    "msg 제작이 끝나면 바로 메세지를 송출하고 결과를 확인하겠습니다\n",
    "\n",
    "---\n",
    "\n",
    "- https://engineering.linecorp.com/ko/blog/line-notify-with-node-js-python-1-basic/\n",
    "\n",
    "사실 Line notify의 경우에는 워낙 간단히 구현할 수 있다보니<br>\n",
    "설명이 잘 되어있고 좋은 자료들이 굉장히 많습니다<br>\n",
    "제 자료뿐만 아니라 상단 링크도 한 번 보시는 것도 추천합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic1](img/pic1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각보다 잘 오는군요!\n",
    "\n",
    "우선 맨 앞에는 줄바꿈 문자를 통해서 새로 시작하는 편이 좋아보입니다<br>\n",
    "그 다음에 예전에 한 것처럼 구분자를 넣어서 각 게시물마다 잘 구분될 수 있도록 합시다\n",
    "\n",
    "흠...제목이니 저자니...시간이니 그런건 딱 봐도 데이터가 구분되니까 이번에는 넣지 말고 해보죠!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "import requests\n",
    "TARGET_URL = 'https://notify-api.line.me/api/notify'\n",
    "TOKEN = 'D1WCgxDEY4ZiFzNR3TFNuCGskQomSTubIfRhAujLrSG'\n",
    "\n",
    "base_url = \"http://www.pknu.ac.kr/usrBoardActn.do?p_bm_idx=5&p_boardcode=PK10000005&p_sbsidx=2\"\n",
    "meta_data = []\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    executable_path=\"webdriver/chromedriver.exe\"\n",
    ")\n",
    "driver.get(base_url)\n",
    "sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"p_sbsidx\"]/option[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"cateForm\"]/div/input').click()\n",
    "\n",
    "for i in range(3):\n",
    "    msg = '\\n'\n",
    "    sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    meta_content = soup.select('td[class=title]')\n",
    "    meta_author = soup.select('td[class=author]')\n",
    "    meta_time = soup.select('td[class=date]')\n",
    "\n",
    "    for tag1, tag2, tag3 in zip(meta_content, meta_author, meta_time):\n",
    "\n",
    "        data_title = tag1.text.strip()\n",
    "        data_author = tag2.text\n",
    "        data_time = tag3.text\n",
    "        status = False\n",
    "        \n",
    "        for temp in meta_data:\n",
    "            if data_title == temp[0]:\n",
    "                status = True\n",
    "                \n",
    "        if status:\n",
    "            continue\n",
    "            \n",
    "        data_author = data_author.replace(\"\\xa0\",\"\")\n",
    "        data_time = data_time.replace(\"\\xa0\", \"\")\n",
    "\n",
    "        meta_data.append([data_title, data_author, data_time])\n",
    "        msg += data_title + '\\n' + data_author + '\\n' + data_time + '\\n' + ('*'*10) + '\\n'\n",
    "        \n",
    "    response = requests.post(\n",
    "  TARGET_URL,\n",
    "  headers={\n",
    "    'Authorization': 'Bearer ' + TOKEN\n",
    "  },\n",
    "  data={\n",
    "    'message':msg\n",
    "  }\n",
    "    )\n",
    "    print(response.text)\n",
    "    driver.find_element_by_xpath('//*[@id=\"contents\"]/div[4]/div[2]/a[' + str(i + 3) + ']').click()\n",
    "\n",
    "t.sleep(2)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic2](img/pic2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 되네요! 다행입니다\n",
    "\n",
    "구분자 길이를 조금 더 늘려주고... 부서 앞에는 -를 붙여주면 좀 더 가독성이 있겠군요!<br>\n",
    "숫자가 하이퍼링크처럼 보이는 문제가 있긴 하지만 거의 문제없어 보입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "import requests\n",
    "TARGET_URL = 'https://notify-api.line.me/api/notify'\n",
    "TOKEN = 'D1WCgxDEY4ZiFzNR3TFNuCGskQomSTubIfRhAujLrSG'\n",
    "\n",
    "base_url = \"http://www.pknu.ac.kr/usrBoardActn.do?p_bm_idx=5&p_boardcode=PK10000005&p_sbsidx=2\"\n",
    "meta_data = []\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    executable_path=\"webdriver/chromedriver.exe\"\n",
    ")\n",
    "driver.get(base_url)\n",
    "sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"p_sbsidx\"]/option[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"cateForm\"]/div/input').click()\n",
    "\n",
    "for i in range(3):\n",
    "    msg = '\\n'\n",
    "    sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    meta_content = soup.select('td[class=title]')\n",
    "    meta_author = soup.select('td[class=author]')\n",
    "    meta_time = soup.select('td[class=date]')\n",
    "\n",
    "    for tag1, tag2, tag3 in zip(meta_content, meta_author, meta_time):\n",
    "\n",
    "        data_title = tag1.text.strip()\n",
    "        data_author = tag2.text\n",
    "        data_time = tag3.text\n",
    "        status = False\n",
    "        \n",
    "        for temp in meta_data:\n",
    "            if data_title == temp[0]:\n",
    "                status = True\n",
    "                \n",
    "        if status:\n",
    "            continue\n",
    "            \n",
    "        data_author = data_author.replace(\"\\xa0\",\"\")\n",
    "        data_time = data_time.replace(\"\\xa0\", \"\")\n",
    "\n",
    "        meta_data.append([data_title, data_author, data_time])\n",
    "        msg += data_title + '\\n - ' + data_author + '\\n' + data_time + '\\n' + ('*'*40) + '\\n'\n",
    "        \n",
    "    response = requests.post(\n",
    "  TARGET_URL,\n",
    "  headers={\n",
    "    'Authorization': 'Bearer ' + TOKEN\n",
    "  },\n",
    "  data={\n",
    "    'message':msg\n",
    "  }\n",
    "    )\n",
    "    print(response.text)\n",
    "    driver.find_element_by_xpath('//*[@id=\"contents\"]/div[4]/div[2]/a[' + str(i + 3) + ']').click()\n",
    "\n",
    "t.sleep(2)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic3](img/pic3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 구분자 길이를 조절하고 날짜 앞에도 -를 붙여주고 끝내겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n",
      "{\"status\":200,\"message\":\"ok\"}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "import requests\n",
    "TARGET_URL = 'https://notify-api.line.me/api/notify'\n",
    "TOKEN = 'D1WCgxDEY4ZiFzNR3TFNuCGskQomSTubIfRhAujLrSG'\n",
    "\n",
    "base_url = \"http://www.pknu.ac.kr/usrBoardActn.do?p_bm_idx=5&p_boardcode=PK10000005&p_sbsidx=2\"\n",
    "meta_data = []\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    executable_path=\"webdriver/chromedriver.exe\"\n",
    ")\n",
    "driver.get(base_url)\n",
    "sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"p_sbsidx\"]/option[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"cateForm\"]/div/input').click()\n",
    "\n",
    "for i in range(3):\n",
    "    msg = '\\n'\n",
    "    sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    meta_content = soup.select('td[class=title]')\n",
    "    meta_author = soup.select('td[class=author]')\n",
    "    meta_time = soup.select('td[class=date]')\n",
    "\n",
    "    for tag1, tag2, tag3 in zip(meta_content, meta_author, meta_time):\n",
    "\n",
    "        data_title = tag1.text.strip()\n",
    "        data_author = tag2.text\n",
    "        data_time = tag3.text\n",
    "        status = False\n",
    "        \n",
    "        for temp in meta_data:\n",
    "            if data_title == temp[0]:\n",
    "                status = True\n",
    "                \n",
    "        if status:\n",
    "            continue\n",
    "            \n",
    "        data_author = data_author.replace(\"\\xa0\",\"\")\n",
    "        data_time = data_time.replace(\"\\xa0\", \"\")\n",
    "\n",
    "        meta_data.append([data_title, data_author, data_time])\n",
    "        msg += data_title + '\\n - ' + data_author + '\\n - ' + data_time + '\\n' + ('*'*39) + '\\n'\n",
    "        \n",
    "    response = requests.post(\n",
    "  TARGET_URL,\n",
    "  headers={\n",
    "    'Authorization': 'Bearer ' + TOKEN\n",
    "  },\n",
    "  data={\n",
    "    'message':msg\n",
    "  }\n",
    "    )\n",
    "    print(response.text)\n",
    "    driver.find_element_by_xpath('//*[@id=\"contents\"]/div[4]/div[2]/a[' + str(i + 3) + ']').click()\n",
    "\n",
    "t.sleep(2)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic4](img/pic4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각하지도 못한 문제가 하나 있네요...\n",
    "\n",
    "라인 메세지에는 글자수 제한이 있는 것 같습니다<br>\n",
    "모든 내용이 현재 메세지로 전달이 안되고 있네요...\n",
    "\n",
    "이러면 어떻게 한다...음..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "여기까지 부경대 웹 홈페이지 공지사항을 전해주는 Line 메세지 알람을 만들어보자였습니다\n",
    "\n",
    "감사합니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
